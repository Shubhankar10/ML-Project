{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRA2UOj+tUU2OuGAcDHvlq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shubhankar10/ML-Project/blob/main/SpeakerVerification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "t-NV9inAKcn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujxArnHXJI_Y"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/drive/MyDrive/ML/SpeakerVerification_Folder/SpeakerVerification'\n",
        "\n",
        "len(os.listdir(dataset_path))"
      ],
      "metadata": {
        "id": "OEAVHeFNKI8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "/dataset_path/\n",
        "  /speaker_folder/\n",
        "    /session_folder/\n",
        "      audio_1.wav\n",
        "      audio_2.wav\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "01gujLhvoIc1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "dict(dict(list))\n",
        "\n",
        "all_data_dict =\n",
        "{\n",
        "  'spekaer_id' :\n",
        "    {\n",
        "      'session_1' : [list of audio file NAMES],\n",
        "      'session_2' : [list of audio file NAMES]\n",
        "      ...\n",
        "    },\n",
        "  'spekaer_id' :\n",
        "  {\n",
        "    'session_1' : [list of audio file NAMES],\n",
        "    'session_2' : [list of audio file NAMES]\n",
        "    ...\n",
        "  }\n",
        "  ...\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "SI3hOcqIohlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of speaker subdirectories\n",
        "speaker_dirs = os.listdir(dataset_path)\n",
        "\n",
        "# Choose the first speaker folder for simplicity\n",
        "speaker_1_folder = os.path.join(dataset_path, speaker_dirs[0])\n",
        "\n",
        "# Get a list of session subdirectories inside the first speaker folder\n",
        "session_dirs = os.listdir(speaker_1_folder)\n",
        "\n",
        "# Choose the first session folder\n",
        "session_1_folder = os.path.join(speaker_1_folder, session_dirs[0])\n",
        "\n",
        "# Get the list of .wav files in the session\n",
        "wav_files = [f for f in os.listdir(session_1_folder) if f.endswith('.wav')]\n",
        "\n",
        "# Choose the first .wav file as a sample\n",
        "sample_audio_file = os.path.join(session_1_folder, wav_files[0])\n",
        "\n",
        "print(\"Sample audio file path:\", sample_audio_file)\n"
      ],
      "metadata": {
        "id": "fyLs-bT8Mjxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "all_data_dict = {}\n",
        "\n",
        "for speaker in speaker_dirs:\n",
        "  speaker_path = os.path.join(dataset_path, speaker)\n",
        "  speaker_dict = {}\n",
        "  for folder in os.listdir(speaker_path):\n",
        "    file_list = []\n",
        "    for file in os.listdir(os.path.join(speaker_path, folder)):\n",
        "      file_list.append(file) # yaha path bhi rakh sakte\n",
        "      # file_list.append(os.path.join(speaker_path, folder, file))\n",
        "    speaker_dict[folder] = file_list\n",
        "  all_data_dict[speaker] = speaker_dict\n",
        "\n",
        "# print(all_data_dict)\n",
        "\n"
      ],
      "metadata": {
        "id": "9it6dmUtMDXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_count_per_speaker = [len(os.listdir(os.path.join(dataset_path, speaker))) for speaker in speaker_dirs]\n",
        "\n",
        "plt.bar(speaker_dirs, file_count_per_speaker)\n",
        "plt.xlabel('Speaker ID')\n",
        "plt.ylabel('Number of Audio Files')\n",
        "plt.title('Number of Audio Files per Speaker')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Blylz8WBL360"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Duration Count"
      ],
      "metadata": {
        "id": "9LZEYq1DqAll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "durations = []\n",
        "for folder in os.listdir(speaker_path):\n",
        "  for file in os.listdir(os.path.join(speaker_path, folder)):\n",
        "    y, sr = librosa.load(os.path.join(speaker_path, folder, file), sr=None)\n",
        "    durations.append(librosa.get_duration(y=y, sr=sr))\n",
        "plt.hist(durations, bins=20)\n",
        "plt.xlabel('Duration (seconds)')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of Audio File Durations')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wBp5RoK5nxxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MFSC"
      ],
      "metadata": {
        "id": "aMBa4j99p8F3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa.display\n",
        "\n",
        "y, sr = librosa.load(sample_audio_file, sr=None)\n",
        "S = librosa.feature.melspectrogram(y=y, sr=sr)\n",
        "S_dB = librosa.power_to_db(S, ref=np.max)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "librosa.display.specshow(S_dB, sr=sr, x_axis='time', y_axis='mel')\n",
        "plt.colorbar(format='%+2.0f dB')\n",
        "plt.title('Mel-Spectrogram')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ej8mWYdHMQlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MFCC"
      ],
      "metadata": {
        "id": "31P0IzVvqWQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa.display\n",
        "\n",
        "# Load the audio file\n",
        "y, sr = librosa.load(sample_audio_file, sr=None)\n",
        "\n",
        "# Compute the MFCCs (usually we extract 13 MFCCs)\n",
        "mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "\n",
        "# Plot the MFCCs\n",
        "plt.figure(figsize=(10, 4))\n",
        "librosa.display.specshow(mfccs, sr=sr, x_axis='time')\n",
        "plt.colorbar()\n",
        "plt.title('MFCC')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YLDewCeJqVwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rms = librosa.feature.rms(y=y)\n",
        "plt.semilogy(rms.T, label='RMS Energy')\n",
        "plt.xticks([])\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Energy')\n",
        "plt.title('RMS Energy Over Time')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "q6OcVp3RMX0S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}